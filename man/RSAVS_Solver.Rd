% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RSAVS_Path.R
\name{RSAVS_Solver}
\alias{RSAVS_Solver}
\title{Robust subgroup analysis and variable selection simultaneously}
\usage{
RSAVS_Solver(
  y_vec,
  x_mat,
  l_type = "L1",
  l_param = NULL,
  p1_type = "S",
  p1_param = c(2, 3.7),
  p2_type = "S",
  p2_param = c(2, 3.7),
  const_r123,
  const_abc = rep(1, 3),
  initial_values,
  additional,
  tol = 0.001,
  max_iter = 10,
  cd_max_iter = 1,
  cd_tol = 0.001,
  phi = 1,
  subgroup_benchmark = FALSE,
  update_mu = NULL,
  loss_track = FALSE,
  diff_update = TRUE,
  omp_zsw = c(1, 4, 1),
  eigen_pnum = 1,
  s_v2 = TRUE
)
}
\arguments{
\item{y_vec}{numerical vector of response. n = length(y_vec) is the number of observations.}

\item{x_mat}{numerical matrix of covariates. Each row for one observation and 
\code{p = ncol(x_mat)} is the number of covariates.}

\item{l_type}{character string, type of loss function.
\itemize{
  \item "L1": l-1 loss(absolute value loss)
  \item "L2": l-2 loss(squared error loss)
  \item "Huber": Huber loss. Its parameter is given in l_param.
}
Default value is "L1".}

\item{l_param}{numeric vector containing necessary parameters of the corresponding loss function. 
The default value is \code{NULL}.}

\item{p1_type, p2_type}{a character indicating the penalty types for subgroup identification and variable selection.
\itemize{
  \item "S": SCAD
  \item "M": MCP
  \item "L": Lasso
}
Default values for both parameters are "S".}

\item{p1_param, p2_param}{numerical vectors providing necessary parameters for the corresponding penalties.
\itemize{
  \item For Lasso, lam = p_param[1]
  \item For SCAD and MCP, lam = p_param[1], gamma = p_param[2]
}
Default values for both parameters are \code{c(2, 3.7)}. 
Note: This function searches the whole lam1_vec * lam2_vec grid for the best solution. 
Hence the \code{lambda}s provided in these parameters serve only as placeholder 
and will be ignored and overwritten in the actual computation.}

\item{const_r123}{a length-3 numerical vector, providing the scalars needed in the 
augmented lagrangian part of the ADMM algorithm}

\item{const_abc}{a length-3 numeric vector, providing the scalars to adjust weight
of regression function, penalty for subgroup identification and penalty for 
variable selection in the overall objective function. Defaults to \code{c(1, 1, 1)}.}

\item{initial_values}{list of vector, providing initial values for the algorithm.}

\item{additional}{a list providing additional variables needed during the algorithm.}

\item{tol}{numerical, convergence tolerance for the algorithm.}

\item{max_iter}{integer, max number of iteration during the algorithm.}

\item{cd_max_iter}{integer, max number of iteration during the coordinate descent
update of \code{mu} and \code{beta}. If set to 0, will use analytical solution(
instead of coordinate descent algorithm) to update \code{mu} and \code{beta}.}

\item{cd_tol}{numerical, convergence tolerance for the coordinate descent part 
when updating \code{mu} and \code{beta}.}

\item{phi}{numerical variable. A parameter needed for mBIC.}

\item{subgroup_benchmark}{bool. Whether this call should be taken as a benchmark of subgroup identification. 
If \code{TRUE}, then the penalty for variable selection will be surpressed to a minimal value.}

\item{update_mu}{list of parameters for updating \code{mu_vec} in the algorithm into meaningful subgroup structure.
Defaults to \code{NULL}, which means there is no update performed. The update of \code{mu_vec} is carried out through
\code{RSAVS_Determine_Mu} and the necessary parameters in \code{update_mu} are:
\itemize{
  \item \code{UseS}: a bool variable, whether the \code{s_vec} should be used to provide subgroup structure information.
  \item \code{klim}: a length-3 integer vector, given the range of number of cluster for considering.
  \item \code{usepam}: a bool variable, whether to use \code{pam} for clustering.
  \item \code{round_digits}: non-negative integer digits, indicating the rounding digits when merging \code{mu_vec}
}
Please refer to \code{RSAVS_Determine_Mu} to find out more details about how the algorithm works}

\item{loss_track}{boolen, whether to track the value of objective function(loss value) during each iteration.}

\item{diff_update}{boolen, whether to update the difference between each iteration. If set to \code{FALSE},
the algorithm will still stop when it reaches \code{max_iter}.}

\item{omp_zsw}{a length-three integer vector, defaults to \code{c(1, 4, 1)}. It represents how many
parallel threads to be used during the update of \code{z}, \code{s} and \code{w} respectively.}

\item{eigen_pnum}{integer number, representing the number of Eigen threads for matrix computation, 
defaults to 4.}

\item{s_v2}{boolen, whether to use the updated and faster version during the computation of 
\code{s} and \code{q2}}

\item{lam1_vec, lam2_vec}{numerical vectors of customized lambda vectors. 
For \code{lam1_vec}, it's preferred to be in the order from small to big.}

\item{min_lam_ratio}{the ratio between the minimal and maximal lambda, equals to (minimal lambda) / (maximal lambda).
The default value is 0.03.}

\item{lam1_len, lam2_len}{integers, lengths of the auto-generated lambda vectors.}
}
\description{
This function utilize the cpp solver when carring out robust subgroup 
  analysis and variable selection simultaneously. And it is the core solver
  for \code{\link{RSAVS_Path}}.
}
\seealso{
\code{\link{RSAVS_Path}}, \code{\link{RSAVS_Path_PureR}}, \code{\link{RSAVS_LargeN}}
}
